---
title: "Tint Is Not Tufte"
subtitle: "An implementation in R Markdown"
author: "JJ Allaire, Yihui Xie, Dirk Eddelbuettel"
date: "`r Sys.Date()`"
output: tint::tintHtml
bibliography: skeleton.bib
link-citations: yes
---

```{r setup, include=FALSE}
library(tint)
# invalidate cache when the package version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tint'))
options(htmltools.dir.version = FALSE)
```

# Introduction

The American Statistical Association (ASA) released a statement in March urging the scientific community to abandon the use of the phrase "statistically significant." Specifically, it said, 

> We conclude, based on our review of the articles in this special issue and the broader literature, that it is time to stop using the term “statistically significant” entirely. Nor should variants such as “significantly different,” “p < 0.05,” and “nonsignificant” survive, whether expressed in words, by asterisks in a table, or in some other way.
> 
> `r tint::quote_footer('--- Ron Wasserstein, Allen Schirm, and Nicole Lazar')`

Why did the ASA make this recommendation? Well, earlier in the editorial they mention the following:

> If you’re just arriving to the debate, here’s a sampling of what not to do:

> •  Don’t base your conclusions solely on whether an association or effect was found to be “statistically significant” (i.e., the p-value passed some arbitrary threshold such as $p < 0.05$).  
> •  Don’t believe that an association or effect exists just because it was statistically significant.  
> •  Don’t believe that an association or effect is absent just because it was not statistically significant.  
> •  Don’t believe that your p-value gives the probability that chance alone produced the observed association or effect or the probability that your test hypothesis is true.  
> •  Don’t conclude anything about scientific or practical importance based on statistical significance (or lack thereof)

# The problem

So statisticians are telling me I'm wrong...again! What am I supposed to do?

> Don’t. Don’t. Just...don’t. Yes, we talk a lot about don’ts. The ASA Statement on p-Values and Statistical Significance (Wasserstein and Lazar 2016) was developed primarily because after decades, warnings about the don’ts had gone mostly unheeded. The statement was about what not to do, because there is widespread agreement about the don’ts. Knowing what not to do with p-values is indeed necessary, but it does not suffice. It is as though statisticians were asking users of statistics to tear out the beams and struts holding up the edifice of modern scientific research without offering solid construction materials to replace them. Pointing out old, rotting timbers was a good start, but now we need more.


# 3 recommendations for what to do

## 1. Talk about risk/odds/hazard ratios that are consistent with the data


## 2. Ask yourself, "Did I learn anything?"



## 3. Avoid treating statistics as "uncertainty laundering" 

`r margin_note("Term 'uncertainty laundering' comes from Andrew Gelman in this same editorial as well as at https://statmodeling.stat.columbia.edu/2016/03/07/29212/")`

# How to do it

## Rewriting a results section

## Responding to a journal reviewer

# How the world could be different